# üìå Import pustaka yang dibutuhkan
import pandas as pd
import re
import string
import nltk
import shutil  # Untuk menghapus cache NLTK jika bermasalah
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from google.colab import files  # Untuk upload & download dataset di Google Colab
from tqdm import tqdm  # Untuk progress bar

# üîπ Coba hapus cache NLTK jika sebelumnya bermasalah
try:
    shutil.rmtree("/root/nltk_data")  # Hapus cache NLTK
    print("Cache NLTK dihapus, mengunduh ulang resource...")
except FileNotFoundError:
    print("Tidak ada cache NLTK yang perlu dihapus.")

# üîπ Download ulang resource NLTK
nltk.download('punkt')
nltk.download('stopwords')
# Ensure the 'stopwords' dataset is downloaded
nltk.download('stopwords') # Download the stopwords dataset

nltk.download('punkt_tab')  # Tambahan jika tetap error

# Cek apakah resource sudah terunduh dengan benar
try:
    print("Cek resource punkt:", nltk.data.find('tokenizers/punkt'))
except LookupError:
    print("Resource punkt tidak ditemukan, harap ulangi pengunduhan!")

# 1Ô∏è‚É£ **UPLOAD DATASET (KHUSUS UNTUK GOOGLE COLAB)**
print("Silakan upload file dataset (contoh: reviews.csv)")
uploaded = files.upload()  # Tunggu hingga file diunggah

# 2Ô∏è‚É£ **BACA DATASET YANG DIUNGGAH**
file_name = list(uploaded.keys())[0]  # Ambil nama file yang diupload
df = pd.read_csv(file_name, encoding="latin1")  # Membaca file CSV

# 3Ô∏è‚É£ **LIHAT INFORMASI DATASET**
print("\nüîπ Informasi Dataset:")
print(df.info())

# 4Ô∏è‚É£ **PILIH KOLOM TEKS UNTUK DIPROSES**
if 'Review' not in df.columns:
    raise KeyError("Kolom 'Review' tidak ditemukan dalam dataset. Pastikan nama kolom benar.")

df = df[['Review']].dropna()  # Menghapus baris yang memiliki nilai kosong (NaN)

# 5Ô∏è‚É£ **Inisialisasi stopwords dan stemmer hanya sekali (lebih efisien)**
# Download the 'stopwords' resource if it hasn't been downloaded already.
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

# 6Ô∏è‚É£ **FUNGSI PEMROSESAN TEKS (Optimal & Lebih Cepat)**
def preprocess_text(text):
    # **1Ô∏è‚É£ Case Folding**: Ubah semua teks menjadi huruf kecil
    text = text.lower()
    
    # **2Ô∏è‚É£ Removing Punctuation**: Hapus tanda baca
    text = text.translate(str.maketrans("", "", string.punctuation))
    
    # **3Ô∏è‚É£ Tokenization & Removing Stop Words**: Tokenisasi dan hapus stopwords
    words = word_tokenize(text)  # üöÄ Pakai tokenizer yang sudah diunduh
    filtered_words = [word for word in words if word not in stop_words]
    
    # **4Ô∏è‚É£ Stemming**: Ubah kata ke bentuk dasarnya
    stemmed_words = [stemmer.stem(word) for word in filtered_words]
    
    return " ".join(stemmed_words)

# 7Ô∏è‚É£ **APLIKASIKAN PEMROSESAN TEKS KE ULASAN (Dengan Progress Bar)**
tqdm.pandas()
df['cleaned_review'] = df['Review'].astype(str).progress_apply(preprocess_text)

# 8Ô∏è‚É£ **LIHAT HASIL SETELAH PREPROCESSING**
print("\nüîπ Contoh Hasil Preprocessing:")
print(df[['Review', 'cleaned_review']].head())

# 9Ô∏è‚É£ **SIMPAN DATASET YANG TELAH DIPROSES**
df.to_csv("cleaned_reviews.csv", index=False)

print("\n‚úÖ Pemrosesan teks selesai! Dataset yang telah diproses disimpan sebagai 'cleaned_reviews.csv'")

# üîü **TOMBOL DOWNLOAD FILE**
files.download("cleaned_reviews.csv")  # Otomatis menampilkan tombol download di Google Colab